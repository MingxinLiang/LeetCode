{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tce3stUlHN0L"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:22.576181Z",
     "iopub.status.busy": "2021-08-13T19:53:22.575567Z",
     "iopub.status.idle": "2021-08-13T19:53:22.578343Z",
     "shell.execute_reply": "2021-08-13T19:53:22.578724Z"
    },
    "id": "tuOe1ymfHZPu"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFdPvlXBOdUN"
   },
   "source": [
    "# 梯度和自动微分简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6P32iYYV27b"
   },
   "source": [
    "## 自动微分和梯度\n",
    "\n",
    "[自动微分](https://en.wikipedia.org/wiki/Automatic_differentiation)对于实现机器学习算法（例如，用于训练神经网络的[反向传播](https://en.wikipedia.org/wiki/Backpropagation)）非常有用。\n",
    "\n",
    "在本指南中，您将探索使用 TensorFlow 计算梯度的方法，尤其是在 [Eager Execution](eager.ipynb) 中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUXex9ctTuDB"
   },
   "source": [
    "## 设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:22.586100Z",
     "iopub.status.busy": "2021-08-13T19:53:22.585491Z",
     "iopub.status.idle": "2021-08-13T19:53:24.518330Z",
     "shell.execute_reply": "2021-08-13T19:53:24.517804Z"
    },
    "id": "IqR2PQG4ZaZ0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHxb-dlhMIzW"
   },
   "source": [
    "## 计算梯度\n",
    "\n",
    "要实现自动微分，TensorFlow 需要记住在*前向*传递过程中哪些运算以何种顺序发生。随后，在*后向传递*期间，TensorFlow 以相反的顺序遍历此运算列表来计算梯度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CLWJl0QliB0"
   },
   "source": [
    "## 梯度带\n",
    "\n",
    "TensorFlow 为自动微分提供了 `tf.GradientTape` API；即计算某个计算相对于某些输入（通常是 `tf.Variable`）的梯度。TensorFlow 会将在 `tf.GradientTape` 上下文内执行的相关运算“记录”到“条带”上。TensorFlow 随后会该使用条带通过[反向模式微分](https://en.wikipedia.org/wiki/Automatic_differentiation)计算“记录的”计算的梯度。\n",
    "\n",
    "例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:24.523011Z",
     "iopub.status.busy": "2021-08-13T19:53:24.522415Z",
     "iopub.status.idle": "2021-08-13T19:53:26.074976Z",
     "shell.execute_reply": "2021-08-13T19:53:26.074515Z"
    },
    "id": "Xq9GgTCP7a4A"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 19:04:28.724565: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-25 19:04:28.771206: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f847f196210 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-25 19:04:28.771225: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CR9tFAP_7cra"
   },
   "source": [
    "记录一些运算后，使用 `GradientTape.gradient(target, sources)` 计算某个目标（通常是损失）相对于某个源（通常是模型变量）的梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.079740Z",
     "iopub.status.busy": "2021-08-13T19:53:26.079211Z",
     "iopub.status.idle": "2021-08-13T19:53:26.085746Z",
     "shell.execute_reply": "2021-08-13T19:53:26.085313Z"
    },
    "id": "LsvrwF6bHroC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dy = 2x * dx\n",
    "dy_dx = tape.gradient(y, x)\n",
    "dy_dx.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2_aqsO25Vx1"
   },
   "source": [
    "上方示例使用标量，但是 `tf.GradientTape` 在任何张量上都可以轻松运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.091077Z",
     "iopub.status.busy": "2021-08-13T19:53:26.090528Z",
     "iopub.status.idle": "2021-08-13T19:53:26.486381Z",
     "shell.execute_reply": "2021-08-13T19:53:26.485786Z"
    },
    "id": "vacZ3-Ws5VdV"
   },
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random.normal((3, 2)), name='w')\n",
    "b = tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')\n",
    "x = [[1., 2., 3.]]\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  y = x @ w + b\n",
    "  loss = tf.reduce_mean(y**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4eXOkrQ-9Pb"
   },
   "source": [
    "要获得 `loss` 相对于两个变量的梯度，可以将这两个变量同时作为 `gradient` 方法的源传递。梯度带在关于源的传递方式上非常灵活，可以接受列表或字典的任何嵌套组合，并以相同的方式返回梯度结构（请参阅 `tf.nest`）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.491468Z",
     "iopub.status.busy": "2021-08-13T19:53:26.490918Z",
     "iopub.status.idle": "2021-08-13T19:53:26.495516Z",
     "shell.execute_reply": "2021-08-13T19:53:26.495059Z"
    },
    "id": "luOtK1Da_BR0"
   },
   "outputs": [],
   "source": [
    "[dl_dw, dl_db] = tape.gradient(loss, [w, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ei4iVXi6qgM7"
   },
   "source": [
    "相对于每个源的梯度具有源的形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.499659Z",
     "iopub.status.busy": "2021-08-13T19:53:26.499128Z",
     "iopub.status.idle": "2021-08-13T19:53:26.501518Z",
     "shell.execute_reply": "2021-08-13T19:53:26.501892Z"
    },
    "id": "aYbWRFPZqk4U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "print(w.shape)\n",
    "print(dl_dw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI_SzxHsvao1"
   },
   "source": [
    "此处也为梯度计算，这一次传递了一个变量字典："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.506134Z",
     "iopub.status.busy": "2021-08-13T19:53:26.505567Z",
     "iopub.status.idle": "2021-08-13T19:53:26.511329Z",
     "shell.execute_reply": "2021-08-13T19:53:26.510908Z"
    },
    "id": "d73cY6NOuaMd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 2.8730934, -1.5158954], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_vars = {\n",
    "    'w': w,\n",
    "    'b': b\n",
    "}\n",
    "\n",
    "grad = tape.gradient(loss, my_vars)\n",
    "grad['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZ2LvHifEMgO"
   },
   "source": [
    "## 相对于模型的梯度\n",
    "\n",
    "通常将 `tf.Variables` 收集到 `tf.Module` 或其子类之一（`layers.Layer`、`keras.Model`）中，用于[设置检查点](checkpoint.ipynb)和[导出](saved_model.ipynb)。\n",
    "\n",
    "在大多数情况下，需要计算相对于模型的可训练变量的梯度。 由于 `tf.Module` 的所有子类都在 `Module.trainable_variables` 属性中聚合其变量，您可以用几行代码计算这些梯度： "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.516246Z",
     "iopub.status.busy": "2021-08-13T19:53:26.515710Z",
     "iopub.status.idle": "2021-08-13T19:53:26.653857Z",
     "shell.execute_reply": "2021-08-13T19:53:26.653319Z"
    },
    "id": "JvesHtbQESc-"
   },
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(2, activation='relu')\n",
    "x = tf.constant([[1., 2., 3.]])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  # Forward pass\n",
    "  y = layer(x)\n",
    "  loss = tf.reduce_mean(y**2)\n",
    "\n",
    "# Calculate gradients with respect to every trainable variable\n",
    "grad = tape.gradient(loss, layer.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.658330Z",
     "iopub.status.busy": "2021-08-13T19:53:26.657736Z",
     "iopub.status.idle": "2021-08-13T19:53:26.660175Z",
     "shell.execute_reply": "2021-08-13T19:53:26.660544Z"
    },
    "id": "PR_ezr6UFrpI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense/kernel:0, shape: (3, 2)\n",
      "dense/bias:0, shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "for var, g in zip(layer.trainable_variables, grad):\n",
    "  print(f'{var.name}, shape: {g.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6Gx6LS714zR"
   },
   "source": [
    "<a id=\"watches\"></a>\n",
    "\n",
    "## 控制梯度带监视的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4VlqKFzzGaC"
   },
   "source": [
    "默认行为是在访问可训练 `tf.Variable` 后记录所有运算。原因如下：\n",
    "\n",
    "- 条带需要知道在前向传递中记录哪些运算，以计算后向传递中的梯度。\n",
    "- 梯度带包含对中间输出的引用，因此应避免记录不必要的操作。\n",
    "- 最常见用例涉及计算损失相对于模型的所有可训练变量的梯度。\n",
    "\n",
    "以下示例无法计算梯度，因为默认情况下 `tf.Tensor` 未被“监视”，并且 `tf.Variable` 不可训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.666226Z",
     "iopub.status.busy": "2021-08-13T19:53:26.665548Z",
     "iopub.status.idle": "2021-08-13T19:53:26.671014Z",
     "shell.execute_reply": "2021-08-13T19:53:26.671354Z"
    },
    "id": "Kj9gPckdB37a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# A trainable variable\n",
    "x0 = tf.Variable(3.0, name='x0')\n",
    "# Not trainable\n",
    "x1 = tf.Variable(3.0, name='x1', trainable=False)\n",
    "# Not a Variable: A variable + tensor returns a tensor.\n",
    "x2 = tf.Variable(2.0, name='x2') + 1.0\n",
    "# Not a variable\n",
    "x3 = tf.constant(3.0, name='x3')\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = (x0**2) + (x1**2) + (x2**2)\n",
    "\n",
    "grad = tape.gradient(y, [x0, x1, x2, x3])\n",
    "\n",
    "for g in grad:\n",
    "  print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkcpQnLgNxgi"
   },
   "source": [
    "您可以使用 `GradientTape.watched_variables` 方法列出梯度带正在监视的变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.675419Z",
     "iopub.status.busy": "2021-08-13T19:53:26.674880Z",
     "iopub.status.idle": "2021-08-13T19:53:26.677743Z",
     "shell.execute_reply": "2021-08-13T19:53:26.678110Z"
    },
    "id": "hwNwjW1eAkib"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x0:0']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[var.name for var in tape.watched_variables()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NB9I1uFvB4tf"
   },
   "source": [
    "`tf.GradientTape` 提供了钩子，让用户可以控制被监视或不被监视的内容。\n",
    "\n",
    "要记录相对于 `tf.Tensor` 的梯度，您需要调用 `GradientTape.watch(x)`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.682653Z",
     "iopub.status.busy": "2021-08-13T19:53:26.682106Z",
     "iopub.status.idle": "2021-08-13T19:53:26.685279Z",
     "shell.execute_reply": "2021-08-13T19:53:26.685642Z"
    },
    "id": "tVN1QqFRDHBK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "  tape.watch(x)\n",
    "  y = x**2\n",
    "\n",
    "# dy = 2x * dx\n",
    "dy_dx = tape.gradient(y, x)\n",
    "print(dy_dx.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxsiYnf2DN8K"
   },
   "source": [
    "相反，要停用监视所有 `tf.Variables` 的默认行为，请在创建梯度带时设置 `watch_accessed_variables=False`。此计算使用两个变量，但仅连接其中一个变量的梯度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.691072Z",
     "iopub.status.busy": "2021-08-13T19:53:26.690551Z",
     "iopub.status.idle": "2021-08-13T19:53:26.693750Z",
     "shell.execute_reply": "2021-08-13T19:53:26.694076Z"
    },
    "id": "7QPzwWvSEwIp"
   },
   "outputs": [],
   "source": [
    "x0 = tf.Variable(0.0)\n",
    "x1 = tf.Variable(10.0)\n",
    "\n",
    "with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "  tape.watch(x1)\n",
    "  y0 = tf.math.sin(x0)\n",
    "  y1 = tf.nn.softplus(x1)\n",
    "  y = y0 + y1\n",
    "  ys = tf.reduce_sum(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRduLbE1H2IJ"
   },
   "source": [
    "由于 `GradientTape.watch` 未在 `x0` 上调用，未相对于它计算梯度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.698621Z",
     "iopub.status.busy": "2021-08-13T19:53:26.698119Z",
     "iopub.status.idle": "2021-08-13T19:53:26.701232Z",
     "shell.execute_reply": "2021-08-13T19:53:26.700847Z"
    },
    "id": "e6GM-3evH1Sz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx0: None\n",
      "dy/dx1: 0.9999546\n"
     ]
    }
   ],
   "source": [
    "# dys/dx1 = exp(x1) / (1 + exp(x1)) = sigmoid(x1)\n",
    "grad = tape.gradient(ys, {'x0': x0, 'x1': x1})\n",
    "\n",
    "print('dy/dx0:', grad['x0'])\n",
    "print('dy/dx1:', grad['x1'].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2g1nKB6P-OnA"
   },
   "source": [
    "## 中间结果\n",
    "\n",
    "您还可以请求输出相对于 `tf.GradientTape` 上下文中计算的中间值的梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.705535Z",
     "iopub.status.busy": "2021-08-13T19:53:26.704953Z",
     "iopub.status.idle": "2021-08-13T19:53:26.708649Z",
     "shell.execute_reply": "2021-08-13T19:53:26.708258Z"
    },
    "id": "7XaPRAwUyYms"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  tape.watch(x)\n",
    "  y = x * x\n",
    "  z = y * y\n",
    "\n",
    "# Use the tape to compute the gradient of z with respect to the\n",
    "# intermediate value y.\n",
    "# dz_dy = 2 * y and y = x ** 2 = 9\n",
    "print(tape.gradient(z, y).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISkXuY7YzIcS"
   },
   "source": [
    "默认情况下，只要调用 `GradientTape.gradient` 方法，就会释放 `GradientTape` 保存的资源。要在同一计算中计算多个梯度，请创建一个 `persistent=True` 的梯度带。这样一来，当梯度带对象作为垃圾回收时，随着资源的释放，可以对 `gradient` 方法进行多次调用。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.713228Z",
     "iopub.status.busy": "2021-08-13T19:53:26.712716Z",
     "iopub.status.idle": "2021-08-13T19:53:26.716812Z",
     "shell.execute_reply": "2021-08-13T19:53:26.717205Z"
    },
    "id": "zZaCm3-9zVCi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4. 108.]\n",
      "[2. 6.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1, 3.0])\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  tape.watch(x)\n",
    "  y = x * x\n",
    "  z = y * y\n",
    "\n",
    "print(tape.gradient(z, x).numpy())  # 108.0 (4 * x**3 at x = 3)\n",
    "print(tape.gradient(y, x).numpy())  # 6.0 (2 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.720769Z",
     "iopub.status.busy": "2021-08-13T19:53:26.720233Z",
     "iopub.status.idle": "2021-08-13T19:53:26.722387Z",
     "shell.execute_reply": "2021-08-13T19:53:26.721963Z"
    },
    "id": "j8bv_jQFg6CN"
   },
   "outputs": [],
   "source": [
    "del tape   # Drop the reference to the tape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_ZY-9BUB7vX"
   },
   "source": [
    "## 性能说明\n",
    "\n",
    "- 在梯度带上下文内进行运算会有一个微小的开销。对于大多数 Eager Execution 来说，这一成本并不明显，但是您仍然应当仅在需要的地方使用梯度带上下文。\n",
    "\n",
    "- 梯度带使用内存来存储中间结果，包括输入和输出，以便在后向传递中使用。\n",
    "\n",
    "    为了提高效率，某些运算（例如 `ReLU`）不需要保留中间结果，而是在前向传递中进行剪枝。不过，如果在梯度带上使用 `persistent=True`，则*不会丢弃任何内容*，并且峰值内存使用量会更高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dLBpZsJebFq"
   },
   "source": [
    "## 非标量目标的梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pldU9F5duP2"
   },
   "source": [
    "梯度从根本上说是对标量的运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.726793Z",
     "iopub.status.busy": "2021-08-13T19:53:26.726225Z",
     "iopub.status.idle": "2021-08-13T19:53:26.730844Z",
     "shell.execute_reply": "2021-08-13T19:53:26.730401Z"
    },
    "id": "qI0sDV_WeXBb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "-0.25\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(2.0)\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    y0 = x**2\n",
    "    y1 = 1 / x\n",
    "\n",
    "print(tape.gradient(y0, x).numpy())\n",
    "print(tape.gradient(y1, x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COEyYp34fxj4"
   },
   "source": [
    "因此，如果需要多个目标的梯度，则每个源的结果为：\n",
    "\n",
    "- 目标总和的梯度，或等效\n",
    "- 每个目标的梯度总和。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.734853Z",
     "iopub.status.busy": "2021-08-13T19:53:26.733069Z",
     "iopub.status.idle": "2021-08-13T19:53:26.738766Z",
     "shell.execute_reply": "2021-08-13T19:53:26.738250Z"
    },
    "id": "o4a6_YOcfWKS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.75\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(2.0)\n",
    "with tf.GradientTape() as tape:\n",
    "  y0 = x**2\n",
    "  y1 = 1 / x\n",
    "\n",
    "print(tape.gradient({'y0': y0, 'y1': y1}, x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvP-mkBMgbym"
   },
   "source": [
    "类似地，如果目标不是标量，则计算总和的梯度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.743534Z",
     "iopub.status.busy": "2021-08-13T19:53:26.741227Z",
     "iopub.status.idle": "2021-08-13T19:53:26.747350Z",
     "shell.execute_reply": "2021-08-13T19:53:26.747699Z"
    },
    "id": "DArPWqsSh5un"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(2.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = x * [3., 4.]\n",
    "\n",
    "print(tape.gradient(y, x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flDbx68Zh5Lb"
   },
   "source": [
    "这样一来，就可以轻松获取损失集合总和的梯度，或者逐元素损失计算总和的梯度。\n",
    "\n",
    "如果每个条目都需要单独的梯度，请参阅[雅可比矩阵](advanced_autodiff.ipynb#jacobians)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwFswok8RAly"
   },
   "source": [
    "在某些情况下，您可以跳过雅可比矩阵。对于逐元素计算，总和的梯度给出了每个元素相对于其输入元素的导数，因为每个元素都是独立的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.753274Z",
     "iopub.status.busy": "2021-08-13T19:53:26.752361Z",
     "iopub.status.idle": "2021-08-13T19:53:26.760539Z",
     "shell.execute_reply": "2021-08-13T19:53:26.760118Z"
    },
    "id": "JQvk_jnMmTDS"
   },
   "outputs": [],
   "source": [
    "x = tf.linspace(-10.0, 10.0, 200+1)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  tape.watch(x)\n",
    "  y = tf.nn.sigmoid(x)\n",
    "\n",
    "dy_dx = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.782459Z",
     "iopub.status.busy": "2021-08-13T19:53:26.775261Z",
     "iopub.status.idle": "2021-08-13T19:53:26.977979Z",
     "shell.execute_reply": "2021-08-13T19:53:26.978434Z"
    },
    "id": "e_f2QgDPmcPE"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y, label='y')\n",
    "plt.plot(x, dy_dx, label='dy/dx')\n",
    "plt.legend()\n",
    "_ = plt.xlabel('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kADybtQzYj4"
   },
   "source": [
    "## 控制流\n",
    "\n",
    "在执行运算时，由于梯度带会记录这些运算，因此会自然地处理 Python 控制流（例如 `if` 和 `while` 语句）。\n",
    "\n",
    "此处，`if` 的每个分支上使用不同变量。梯度仅连接到使用的变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.985706Z",
     "iopub.status.busy": "2021-08-13T19:53:26.984762Z",
     "iopub.status.idle": "2021-08-13T19:53:26.989900Z",
     "shell.execute_reply": "2021-08-13T19:53:26.990318Z"
    },
    "id": "ciFLizhrrjy7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(1.0)\n",
    "\n",
    "v0 = tf.Variable(2.0)\n",
    "v1 = tf.Variable(2.0)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  tape.watch(x)\n",
    "  if x > 0.0:\n",
    "    result = v0\n",
    "  else:\n",
    "    result = v1**2 \n",
    "\n",
    "dv0, dv1 = tape.gradient(result, [v0, v1])\n",
    "\n",
    "print(dv0)\n",
    "print(dv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKnLaiapsjeP"
   },
   "source": [
    "注意，控制语句本身不可微分，因此对基于梯度的优化器不可见。\n",
    "\n",
    "根据上面示例中 `x` 的值，梯度带将记录 `result = v0` 或 `result = v1**2`。 相对于 `x` 的梯度始终为 `None`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:26.994816Z",
     "iopub.status.busy": "2021-08-13T19:53:26.994117Z",
     "iopub.status.idle": "2021-08-13T19:53:26.997289Z",
     "shell.execute_reply": "2021-08-13T19:53:26.996836Z"
    },
    "id": "8k05WmuAwPm7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "dx = tape.gradient(result, x)\n",
    "\n",
    "print(dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egypBxISAHhx"
   },
   "source": [
    "## 获取 `None` 的梯度\n",
    "\n",
    "当目标未连接到源时，您将获得 `None` 的梯度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:27.002668Z",
     "iopub.status.busy": "2021-08-13T19:53:27.001675Z",
     "iopub.status.idle": "2021-08-13T19:53:27.006330Z",
     "shell.execute_reply": "2021-08-13T19:53:27.005908Z"
    },
    "id": "CU185WDM81Ut"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(2.)\n",
    "y = tf.Variable(3.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  z = y * y\n",
    "print(tape.gradient(z, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZbKpHfBRJym"
   },
   "source": [
    "此处 `z` 显然未连接到 `x`，但可以通过几种不太明显的方式将梯度断开。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHDzDOiQ8xmw"
   },
   "source": [
    "### 1. 使用张量替换变量\n",
    "\n",
    "在[控制梯度带监视内容](#watches)部分中，梯度带会自动监视 `tf.Variable`，但不会监视 `tf.Tensor`。\n",
    "\n",
    "一个常见错误是无意中将 `tf.Variable` 替换为 `tf.Tensor`，而不使用 `Variable.assign` 更新 `tf.Variable`。见下例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:27.011506Z",
     "iopub.status.busy": "2021-08-13T19:53:27.010569Z",
     "iopub.status.idle": "2021-08-13T19:53:27.015835Z",
     "shell.execute_reply": "2021-08-13T19:53:27.015374Z"
    },
    "id": "QPKY4Tn9zX7_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResourceVariable : tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "EagerTensor : None\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(2.0)\n",
    "\n",
    "for epoch in range(2):\n",
    "  with tf.GradientTape() as tape:\n",
    "    y = x+1\n",
    "\n",
    "  print(type(x).__name__, \":\", tape.gradient(y, x))\n",
    "  x = x + 1   # This should be `x.assign_add(1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gwZKxgA97an"
   },
   "source": [
    "### 2.在 TensorFlow 之外进行了计算\n",
    "\n",
    "如果计算退出 TensorFlow，梯度带将无法记录梯度路径。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:27.021351Z",
     "iopub.status.busy": "2021-08-13T19:53:27.020462Z",
     "iopub.status.idle": "2021-08-13T19:53:27.024189Z",
     "shell.execute_reply": "2021-08-13T19:53:27.024569Z"
    },
    "id": "jmoLCDJb_yw1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([[1.0, 2.0],\n",
    "                 [3.0, 4.0]], dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  x2 = x**2\n",
    "\n",
    "  # This step is calculated with NumPy\n",
    "  y = np.mean(x2, axis=0)\n",
    "\n",
    "  # Like most ops, reduce_mean will cast the NumPy array to a constant tensor\n",
    "  # using `tf.convert_to_tensor`.\n",
    "  y = tf.reduce_mean(y, axis=0)\n",
    "\n",
    "print(tape.gradient(y, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3YVfP3R-tp7"
   },
   "source": [
    "### 3.通过整数或字符串获取梯度\n",
    "\n",
    "整数和字符串不可微分。如果计算路径使用这些数据类型，则不会出现梯度。\n",
    "\n",
    "谁也不会期望字符串是可微分的，但是如果不指定 `dtype`，很容易意外创建一个 `int` 常量或变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:27.029623Z",
     "iopub.status.busy": "2021-08-13T19:53:27.028794Z",
     "iopub.status.idle": "2021-08-13T19:53:27.034065Z",
     "shell.execute_reply": "2021-08-13T19:53:27.034446Z"
    },
    "id": "9jlHXHqfASU3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the target tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(10)\n",
    "\n",
    "with tf.GradientTape() as g:\n",
    "  g.watch(x)\n",
    "  y = x * x\n",
    "\n",
    "print(g.gradient(y, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsdP_mTHX9L1"
   },
   "source": [
    "TensorFlow 不会在类型之间自动进行转换，因此，在实践中，您经常会遇到类型错误而不是缺少梯度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WyAZ7C8qCEs6"
   },
   "source": [
    "### 4. 通过有状态对象获取梯度\n",
    "\n",
    "状态会停止梯度。从有状态对象读取时，梯度带只能观察当前状态，而不能观察导致该状态的历史记录。\n",
    "\n",
    "`tf.Tensor` 不可变。张量创建后就不能更改。它有一个*值*，但没有*状态*。目前讨论的所有运算也都无状态：`tf.matmul` 的输出只取决于它的输入。\n",
    "\n",
    "`tf.Variable` 具有内部状态，即它的值。使用变量时，会读取状态。计算相对于变量的梯度是正常操作，但是变量的状态会阻止梯度计算进一步向后移动。 例如：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:27.039708Z",
     "iopub.status.busy": "2021-08-13T19:53:27.038616Z",
     "iopub.status.idle": "2021-08-13T19:53:27.043409Z",
     "shell.execute_reply": "2021-08-13T19:53:27.043811Z"
    },
    "id": "C1tLeeRFE479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x0 = tf.Variable(3.0)\n",
    "x1 = tf.Variable(0.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  # Update x1 = x1 + x0.\n",
    "  x1.assign_add(x0)\n",
    "  # The tape starts recording from x1.\n",
    "  y = x1**2   # y = (x1 + x0)**2\n",
    "\n",
    "# This doesn't work.\n",
    "print(tape.gradient(y, x0))   #dy/dx0 = 2*(x1 + x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKA92-dqF2r-"
   },
   "source": [
    "类似地，`tf.data.Dataset` 迭代器和 `tf.queue` 也有状态，会停止经过它们的张量上的所有梯度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHvcDGIbOj2I"
   },
   "source": [
    "## 未注册梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoc-A6AxVqry"
   },
   "source": [
    "某些 `tf.Operation` 被**注册为不可微分**，将返回 `None`。还有一些则**未注册梯度**。\n",
    "\n",
    "`tf.raw_ops` 页面显示了哪些低级运算已经注册梯度。\n",
    "\n",
    "如果您试图通过一个没有注册梯度的浮点运算获取梯度，梯度带将抛出错误，而不是直接返回 `None`。这样一来，您可以了解某个环节出现问题。\n",
    "\n",
    "例如，`tf.image.adjust_contrast` 函数封装了 `raw_ops.AdjustContrastv2`，此运算可能具有梯度，但未实现该梯度：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:27.050780Z",
     "iopub.status.busy": "2021-08-13T19:53:27.049722Z",
     "iopub.status.idle": "2021-08-13T19:53:27.054436Z",
     "shell.execute_reply": "2021-08-13T19:53:27.053978Z"
    },
    "id": "HSb20FXc_V0U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LookupError: gradient registry has no entry for: AdjustContrastv2\n"
     ]
    }
   ],
   "source": [
    "image = tf.Variable([[[0.5, 0.0, 0.0]]])\n",
    "delta = tf.Variable(0.1)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  new_image = tf.image.adjust_contrast(image, delta)\n",
    "\n",
    "try:\n",
    "  print(tape.gradient(new_image, [image, delta]))\n",
    "  assert False   # This should not happen.\n",
    "except LookupError as e:\n",
    "  print(f'{type(e).__name__}: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDoutjzATiEm"
   },
   "source": [
    "如果需要通过此运算进行微分，则需要实现梯度并注册该梯度（使用 `tf.RegisterGradient`），或者使用其他运算重新实现该函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCTwc_dQXp2W"
   },
   "source": [
    "## 零而不是 None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYDrVogA89eA"
   },
   "source": [
    "在某些情况下，对于未连接的梯度，得到 0 而不是 `None` 会比较方便。您可以使用 `unconnected_gradients` 参数来决定具有未连接的梯度时返回的内容："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T19:53:27.060037Z",
     "iopub.status.busy": "2021-08-13T19:53:27.059022Z",
     "iopub.status.idle": "2021-08-13T19:53:27.063399Z",
     "shell.execute_reply": "2021-08-13T19:53:27.063733Z"
    },
    "id": "U6zxk1sf9Ixx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 0.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([2., 2.])\n",
    "y = tf.Variable(3.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  z = y**2\n",
    "print(tape.gradient(z, x, unconnected_gradients=tf.UnconnectedGradients.ZERO))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Tce3stUlHN0L"
   ],
   "name": "autodiff.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
